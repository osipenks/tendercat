{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fit model to classify sentences by smart similarity\n",
    "\n",
    "\n",
    "### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 88 stop words\n",
      "Loaded 200 stop texts from /home/od13/addons/tender_cat/data/model/trained/1/0stop_text.txt\n",
      "Total 198 stop texts is now in piplene\n",
      "Loaded 1956 training texts from 4 files\n",
      "Character counts in texts: min 3, max 1878,  mean 146.45910020449898\n",
      "\n",
      "Deleted 1 long texts\n",
      "Deleted 1 short texts\n",
      "Deleted 75 stop-texts from training corpus\n",
      "Found 2271 unique tokens in texts\n",
      "476 rare words added to stop list\n",
      "Texts normalized again, stop-words removed from texts\n",
      "Now 1796 tokens in vocabulary\n",
      "\n",
      "24 2-grmas found\n",
      "Now 1814 tokens in vocabulary\n",
      "\n",
      "7 3-grmas found\n",
      "Now 1838 tokens in vocabulary\n",
      "\n",
      "Prepeared train corpus for Doc2vec, 1819 texts\n",
      "Creating model with hyperparameters: vector_sizes 300 epochs 200 window 2 ...\n",
      "\n",
      "Doc2vec model is ready, vocabulary 1834\n",
      "Model saved to /home/od13/addons/tender_cat/data/model/trained/1/deep_sim.mod\n",
      "Loaded 88 stop words\n",
      "Loaded 200 stop texts from /home/od13/addons/tender_cat/data/model/trained/1/0stop_text.txt\n",
      "Total 198 stop texts is now in piplene\n",
      "Model loaded from /home/od13/addons/tender_cat/data/model/trained/1/deep_sim.mod\n",
      "          label_name  text  text_id  file  tender  chr_count  norm_text  \\\n",
      "label_id                                                                  \n",
      "1                  1     5        7     3       2          5          5   \n",
      "2                  1     8       10     3       2          8          8   \n",
      "3                  1    15       17     3       2         15         15   \n",
      "4                  1    11       17     2       1         11         11   \n",
      "5                  1    45       63     3       2         43         44   \n",
      "6                  1    11       15     3       2         11         10   \n",
      "7                  1    16       22     3       2         15         16   \n",
      "8                  1    17       22     3       2         16         17   \n",
      "9                  1    14       19     3       2         13         14   \n",
      "10                 1     3        4     3       2          3          3   \n",
      "11                 1     7        9     3       2          6          6   \n",
      "12                 1    10       12     3       2         10         10   \n",
      "14                 1     1        1     1       1          1          1   \n",
      "17                 1    18       22     3       2         18         18   \n",
      "18                 1     1        1     1       1          1          1   \n",
      "19                 1     3        5     3       2          3          3   \n",
      "20                 1    55       59     3       2         50         55   \n",
      "21                 1     8        8     1       1          7          8   \n",
      "22                 1     7        7     3       2          7          7   \n",
      "23                 1     2        2     1       1          2          2   \n",
      "25                 1     5        7     3       2          5          5   \n",
      "26                 1    17       26     3       2         16         17   \n",
      "27                 1    31       34     3       2         28         31   \n",
      "28                 1     2        2     1       1          2          2   \n",
      "1001               1   877     1488     4       2        309        828   \n",
      "\n",
      "          3gram_text  doc2vec_uid  \n",
      "label_id                           \n",
      "1                  5            7  \n",
      "2                  8           10  \n",
      "3                 15           17  \n",
      "4                 11           17  \n",
      "5                 44           63  \n",
      "6                 10           15  \n",
      "7                 16           22  \n",
      "8                 17           22  \n",
      "9                 14           19  \n",
      "10                 3            4  \n",
      "11                 6            9  \n",
      "12                10           12  \n",
      "14                 1            1  \n",
      "17                18           22  \n",
      "18                 1            1  \n",
      "19                 3            5  \n",
      "20                55           59  \n",
      "21                 8            8  \n",
      "22                 7            7  \n",
      "23                 2            2  \n",
      "25                 5            7  \n",
      "26                17           26  \n",
      "27                31           34  \n",
      "28                 2            2  \n",
      "1001             828         1488  \n",
      "{1: 227.4,\n",
      " 2: 142.125,\n",
      " 3: 75.8,\n",
      " 4: 103.36363636363636,\n",
      " 5: 25.84090909090909,\n",
      " 6: 113.7,\n",
      " 7: 71.0625,\n",
      " 8: 66.88235294117646,\n",
      " 9: 81.21428571428571,\n",
      " 10: 379.0,\n",
      " 11: 189.5,\n",
      " 12: 113.7,\n",
      " 14: 1137.0,\n",
      " 17: 63.166666666666664,\n",
      " 18: 1137.0,\n",
      " 19: 379.0,\n",
      " 20: 20.672727272727272,\n",
      " 21: 142.125,\n",
      " 22: 162.42857142857142,\n",
      " 23: 568.5,\n",
      " 25: 227.4,\n",
      " 26: 66.88235294117646,\n",
      " 27: 36.67741935483871,\n",
      " 28: 568.5,\n",
      " 1001: 1.3731884057971016}\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, unidecode, random, gensim, logging\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "sys.path.append('/home/od13/addons/tender_cat/libcat/mytextpipe/')\n",
    "from mytextpipe import corpus\n",
    "from uk_stemmer import UkStemmer\n",
    "from string import punctuation \n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import joblib \n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import math\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "# Temp\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "class DataPipeline:\n",
    "    \n",
    "    def __init__(self, data_folder=None, trained_folder=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.trained_folder = trained_folder\n",
    "        self.model_path = os.path.join(self.trained_folder, 'deep_sim.mod')\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.ngram = None\n",
    "        self.vectorizer = None\n",
    "        self.train_column = 'norm_text'\n",
    "        self.train_df = None\n",
    "        self.label_stat = None\n",
    "\n",
    "        self.corp = corpus.HTMLCorpusReader('.', stemmer=UkStemmer(), clean_text=True, language='russian')\n",
    "        \n",
    "        # Add stop_words\n",
    "        self.stop_words = self.corp.stop_words.copy()\n",
    "        self.stop_words += ['в', 'на', 'за', 'із', 'та', 'що', 'як', 'грн', 'гривен', 'або', 'якщо', '2020',\n",
    "                    'до', 'про', 'як', 'так', 'для', 'від', 'інш', 'щод', 'іх', 'над', 'цьог', 'дат', 'шт', 'чи', \n",
    "                    'мм', '10', 'також', 'під_час', 'при', 'коп', 'мож', 'ма', 'ціє', 'по', 'післ', 'без', \n",
    "                    'цим', 'наступн', 'це', '20', 'ус', 'сво', 'час', 'тощ', 'номер', 'місц', 'одн', 'под', 'не_пізніш', \n",
    "                    '12', 'дiаметр', 'менш', 'бут', 'окрем', 'будьяк', 'під', 'ум', 'учасник', 'дня',\n",
    "                    '[', ']', 'підпис', 'печатк', 'уповноважено', 'особ', 'раз', 'зі', 'isregistry_keywords', 'рок', 'рік']\n",
    "        print('Loaded {} stop words'.format(len(self.stop_words)))\n",
    "        \n",
    "        # Add stop_texts\n",
    "        self.stop_text = []\n",
    "        if 1==1:\n",
    "            for root, dirs, files in os.walk(self.trained_folder):\n",
    "                for f in files: \n",
    "                    if f.endswith(\"stop_text.txt\"):\n",
    "                        fname = os.path.join(self.trained_folder, f)\n",
    "                        with open(fname, \"r\") as file:\n",
    "                            for line in file:\n",
    "                                line_lst = list(line.strip().split(\" \"))\n",
    "                                txt = ' '.join(line_lst[1:])\n",
    "                                self.stop_text.append(txt)\n",
    "                            print('Loaded {} stop texts from {}'.format(len(self.stop_text), fname))\n",
    "            self.stop_text = list(set(self.stop_text))\n",
    "            print('Total {} stop texts is now in piplene'.format(len(self.stop_text)))\n",
    "\n",
    "    \n",
    "    def is_stop_text(self, txt):\n",
    "        return txt in self.stop_text\n",
    "    \n",
    "    def is_stop_word(self, word):\n",
    "        if len(word)<=1:\n",
    "            return True\n",
    "        if word in ['.', ',', ';', ':', '!', '?']:\n",
    "            return True\n",
    "        if word in self.stop_words:\n",
    "            return True\n",
    "\n",
    "    def nice_word_form(self, word):\n",
    "        # Some special cases\n",
    "        nice_dct = {\n",
    "            'тендерно': 'тендерн',\n",
    "            'тендерні': 'тендерн',\n",
    "            'електронні': 'електронн',\n",
    "            'договор': 'договір',\n",
    "            'статт_17': 'ст17',\n",
    "            'юридично': 'юридичн',\n",
    "            'юридични': 'юридичн',\n",
    "            'антикорупціино': 'антикорупціин',\n",
    "            'банківсько': 'банківськ',\n",
    "            'будь-яко': 'будь-як',\n",
    "            'будь-які': 'будь-як',\n",
    "            'будівельно': 'будівельн',\n",
    "            'бюджетн': 'бюджет',\n",
    "            'вартост': 'вартіст',\n",
    "            'вважают': 'вваж',\n",
    "            'вважаєт': 'вваж',\n",
    "            'вимагал': 'вимаг',\n",
    "            'вимагают': 'вимаг',\n",
    "            'вимагаєт': 'вимаг',\n",
    "            'вимог': 'вимаг',\n",
    "            'випробувальн': 'випробуван',\n",
    "            'випробуванн': 'випробуван',\n",
    "            'виробник': 'виробн',\n",
    "            'виробництв': 'виробн',\n",
    "            'виробнич': 'виробн',\n",
    "            'відповідальност': 'відповідальн',\n",
    "            'відповідальніст': 'відповідальн',\n",
    "            'державно': 'державн',\n",
    "        }\n",
    "        return nice_dct[word] if word in nice_dct else word\n",
    "    \n",
    "    def normalize(self, txt):\n",
    "    \n",
    "        txt = txt.strip()\n",
    "\n",
    "        url_pattern = r'https?://\\S+|http?://\\S+|www\\.\\S+'\n",
    "        txt = re.sub(pattern=url_pattern, repl=' ', string=txt)\n",
    "\n",
    "        #number_pattern = r'\\d+'\n",
    "        #txt = re.sub(pattern=number_pattern, repl=\"nmbr\", string=txt)\n",
    "        #txt = re.sub(pattern=number_pattern, repl=\" \", string=txt)\n",
    "\n",
    "        single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
    "        txt = re.sub(pattern=single_char_pattern, repl=\" \", string=txt)\n",
    "\n",
    "        txt = gensim.utils.decode_htmlentities(gensim.utils.deaccent(txt))\n",
    "\n",
    "        space_pattern = r'\\s+'\n",
    "        txt = re.sub(pattern=space_pattern, repl=\" \", string=txt)\n",
    "\n",
    "        return [self.nice_word_form(x) \n",
    "                for x in self.corp.text_to_words(txt) \n",
    "                if not self.is_stop_word(x)]\n",
    "    \n",
    "    def text_src(self, source_df, column='norm_text'):\n",
    "        # Generator for reading texts of selected column\n",
    "        # Return list of words\n",
    "        for index, row in source_df.iterrows():\n",
    "            txt = str(row[column]).strip()\n",
    "            if txt:\n",
    "                yield txt.split()\n",
    "    \n",
    "    def calc_word_count(self, source_df, column='norm_text'):\n",
    "        word_list = []\n",
    "        for txt in self.text_src(source_df, column):\n",
    "            for word in txt:\n",
    "                word_list.append(word)\n",
    "        word_df = pd.DataFrame(word_list, columns=['word'])\n",
    "        self.word_count = word_df['word'].nunique()\n",
    "        return word_df\n",
    "\n",
    "    def print_most_freq(self, source_df, column, top, reverse=True):\n",
    "        _freq_word_dct = dict(source_df[column].value_counts())\n",
    "        for w in sorted(_freq_word_dct, key=_freq_word_dct.get, reverse=reverse):\n",
    "            print(_freq_word_dct[w], w)\n",
    "            top -= 1\n",
    "            if not top:\n",
    "                break    \n",
    "                \n",
    "    def generate_ngrams(self, source_df, n, min_count=10, threshold=20):\n",
    "        gram_model_filepath = os.path.join(self.trained_folder, str(n)+'gram.mod')\n",
    "        column_name = 'norm_text' if n==2 else str(n)+'gram_text'\n",
    "        prev_column_name = 'norm_text' if (n-1)==1 else str((n-1))+'gram_text'\n",
    "        \n",
    "        gram_model = Phrases(self.text_src(source_df, prev_column_name), min_count, threshold)\n",
    "        gram_list = []\n",
    "        for txt in self.text_src(source_df, prev_column_name):\n",
    "            gram_txt = gram_model[txt]\n",
    "            for word in gram_txt:\n",
    "                if len(word.split('_'))==n:\n",
    "                    gram_list.append(word)\n",
    "        gram_df = pd.DataFrame(gram_list, columns=['word'])\n",
    "        source_df[str(n)+'gram_text'] = source_df.apply(lambda row: ' '.join(gram_model[row[prev_column_name].split()]), axis=1)\n",
    "        \n",
    "        if not prev_column_name == 'norm_text':\n",
    "            del source_df[prev_column_name]\n",
    "            \n",
    "        self.ngram = gram_model\n",
    "        self.train_column = column_name\n",
    "        return gram_df \n",
    "    \n",
    "    def text_src_to_tagged_docs(self, source_df, txt_column='norm_text'):\n",
    "        for index, row in source_df.iterrows():\n",
    "            word_lst = str(row[txt_column]).split()\n",
    "            if word_lst:\n",
    "                if len(word_lst) <= 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    yield gensim.models.doc2vec.TaggedDocument(word_lst, [row['doc2vec_uid']])\n",
    "    \n",
    "    def ivec(self, word_list, epochs=850, alpha=0.025):\n",
    "        if self.vectorizer:\n",
    "            return self.vectorizer.infer_vector(word_list, epochs=epochs)\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def most_similar(self, txt, topn=30):\n",
    "        \n",
    "        similars = []\n",
    "        \n",
    "        if self.ngram:\n",
    "            word_list = self.ngram[self.normalize(txt)]\n",
    "        else:\n",
    "            word_list = self.normalize(txt)\n",
    "        \n",
    "        if len(word_list) == 1:\n",
    "            similars.append({\n",
    "                'id': 0,\n",
    "                'label_name': '?',\n",
    "                'label_id': 1001,\n",
    "                'text': txt,\n",
    "                'train_text': '',\n",
    "                'sim': 0,\n",
    "            })\n",
    "            return similars\n",
    "        \n",
    "        txt_vector = self.ivec(word_list)\n",
    "        sims = self.vectorizer.docvecs.most_similar([txt_vector], topn=topn)\n",
    "\n",
    "        for doc_id, sim in sims:\n",
    "            found_rows = self.train_df[self.train_df.doc2vec_uid == doc_id]\n",
    "            similars.append({\n",
    "                'id': doc_id,\n",
    "                'label_name': found_rows['label_name'],\n",
    "                'label_id': found_rows['label_id'],\n",
    "                'text': found_rows['text'],\n",
    "                'train_text': found_rows[self.train_column],\n",
    "                'sim': sim,\n",
    "            })\n",
    "        \n",
    "        return similars\n",
    "    \n",
    "    def save(self):\n",
    "        joblib.dump({\n",
    "            'ngram': self.ngram,\n",
    "            'vectorizer': self.vectorizer,\n",
    "            'stop_words': self.stop_words,\n",
    "            'stop_text': self.stop_text,\n",
    "            'train_column': self.train_column,\n",
    "            'train_df': self.train_df,\n",
    "            'label_stat': self.label_stat,\n",
    "        }, self.model_path)\n",
    "        print('Model saved to {}'.format(self.model_path))\n",
    "            \n",
    "    def load(self):\n",
    "        model_dct = joblib.load(self.model_path)\n",
    "        self.ngram = model_dct['ngram']\n",
    "        self.vectorizer = model_dct['vectorizer']\n",
    "        self.stop_words = model_dct['stop_words']\n",
    "        self.stop_text = model_dct['stop_text']\n",
    "        self.train_column = model_dct['train_column']\n",
    "        self.train_df = model_dct['train_df']\n",
    "        self.label_stat = model_dct['label_stat']\n",
    "        print('Model loaded from {}'.format(self.model_path))\n",
    "        \n",
    "    def update_label_stat(self):\n",
    "        \n",
    "        tdf = self.train_df\n",
    "        label_freq = {}\n",
    "        label_names = {}\n",
    "        label_norm_freq = {}\n",
    "        total_cnt = 0\n",
    "        max_count = 0\n",
    "        for i, row in tdf.groupby('label_id').nunique().iterrows():\n",
    "            cnt = row[self.train_column]\n",
    "            label_freq[i] = cnt\n",
    "            total_cnt += cnt\n",
    "            \n",
    "            if cnt > max_count:\n",
    "                max_count = cnt\n",
    "            \n",
    "            label_names[i] = tdf.loc[tdf['label_id'] == i, 'label_name'].iloc[0]\n",
    "            # calc unique texts count instead\n",
    "\n",
    "        for label_id in label_freq:\n",
    "            label_norm_freq[label_id] = label_freq[label_id]/max_count\n",
    "            \n",
    "        self.label_stat = {\n",
    "            'freq': label_freq,\n",
    "            'norm_freq': label_norm_freq,\n",
    "            'name': label_names,\n",
    "            'total_cnt': total_cnt,\n",
    "        }\n",
    "    \n",
    "\n",
    "    def text_label(self, txt, stack=20, sim_pow=3, debug=False):\n",
    "        \n",
    "        sims = self.most_similar(txt, topn=stack)\n",
    "        \n",
    "        labels_cnt = {}\n",
    "        labels_sim = {}\n",
    "        \n",
    "        for sim in sims:\n",
    "            try:\n",
    "                label_id = sim['label_id'].iloc[0]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            if label_id in labels_cnt: \n",
    "                labels_cnt[label_id] += 1 \n",
    "                labels_sim[label_id] += math.pow(sim['sim'], sim_pow)\n",
    "            else:\n",
    "                labels_cnt[label_id] = 1 \n",
    "                labels_sim[label_id] = math.pow(sim['sim'], sim_pow)\n",
    "        \n",
    "        labels_score = {}\n",
    "        \n",
    "        for label_id in labels_cnt:\n",
    "            # Fraction of particular label set\n",
    "            norm_freq = labels_cnt[label_id]/self.label_stat['freq'][label_id]\n",
    "            total_norm_freq = norm_freq #/self.label_stat['norm_freq'][label_id]\n",
    "            \n",
    "            # Look at similarity\n",
    "            score = total_norm_freq*labels_sim[label_id]\n",
    "            \n",
    "            labels_score[label_id] = score\n",
    "            \n",
    "        winner_id = sorted(labels_score, key=labels_score.get, reverse=True)[0]\n",
    "        \n",
    "        vals = {\n",
    "            'label_id': winner_id,\n",
    "            'label_name': self.label_stat['name'][winner_id],\n",
    "            \n",
    "        }\n",
    "        \n",
    "        if debug:\n",
    "            sims_name = {}\n",
    "            for w in sorted(labels_score, key=labels_score.get, reverse=True):\n",
    "                sims_name[self.label_stat['name'][w]] = labels_score[w]\n",
    "            vals.update({\n",
    "                'sims': labels_score, \n",
    "                'sims_named': sims_name, \n",
    "                'sim': labels_score[winner_id]\n",
    "            })\n",
    "        \n",
    "        return vals\n",
    " \n",
    "        \n",
    "    def fit(self, data_folder=None, trained_folder=None, a=None):\n",
    "\n",
    "        ################################################\n",
    "        # Load csv\n",
    "        csvs = []\n",
    "        for root, dirs, files in os.walk(self.data_folder):\n",
    "            for f in files: \n",
    "                if f.endswith(\".csv\"):\n",
    "                    try: \n",
    "                        csv = pd.read_csv(os.path.join(self.data_folder, f))\n",
    "                        csvs.append(csv)\n",
    "                    except (FileExistsError, IOError, pd.errors.EmptyDataError) as e:\n",
    "                        _logger.error('{}: {}'.format(f,e))\n",
    "\n",
    "        df = pd.concat(csvs,ignore_index=True)\n",
    "        df.fillna(value = {'label_id': 1001, 'label_name': '?'}, inplace=True)\n",
    "        df.label_id = df.label_id.astype(int)\n",
    "\n",
    "        print('Loaded {} training texts from {} files'.format(df.shape[0], len(set(df['file'].dropna()))))\n",
    "\n",
    "        ################################################\n",
    "        # Characters count\n",
    "        df['chr_count'] = df.apply(lambda row: len(row['text']), axis=1)\n",
    "\n",
    "        stat = {'chr_count_max': df['chr_count'].max(), 'chr_count_min': df['chr_count'].min() }\n",
    "\n",
    "        print('Character counts in texts: min {}, max {},  mean {}\\n'.format(stat['chr_count_min'], stat['chr_count_max'], df['chr_count'].mean()))\n",
    "\n",
    "        ################################################\n",
    "        # Delete too long sentences, max chr count -1\n",
    "        start_len = df.shape[0]\n",
    "        df = df.drop(df[df.chr_count >= stat['chr_count_max']-1].index)\n",
    "        print('Deleted {} long texts'.format(start_len-df.shape[0]))\n",
    "\n",
    "        if 0==1:\n",
    "            top_n = 5\n",
    "            print('\\nTop {} most long now: '.format(top_n))\n",
    "            print(df.sort_values('chr_count', ascending = False)['text'].head(top_n))\n",
    "\n",
    "        ################################################\n",
    "        # Delete too short sentences, chr count == min\n",
    "        start_len = df.shape[0]\n",
    "        max_chr_count = max(3, stat['chr_count_min'])\n",
    "        df = df.drop(df[df.chr_count <= max_chr_count].index)\n",
    "        print('Deleted {} short texts'.format(start_len-df.shape[0]))\n",
    "\n",
    "        if 0==1:\n",
    "            top_n = df.shape[0]//50\n",
    "            print('\\nTop {} most short now: '.format(top_n))\n",
    "            print(df.sort_values('chr_count', ascending = True)['text'].head(top_n))\n",
    "            \n",
    "        ##############################################    \n",
    "        # Generate normalized text, iter 1\n",
    "        df['norm_text'] = df.apply(lambda row: str(' '.join(self.normalize(row['text'])).strip()), axis=1)\n",
    "        \n",
    "        # We may unload most frequent texts to disk here\n",
    "        \n",
    "        ##############################################    \n",
    "        # Delete stop_texts\n",
    "        start_len = df.shape[0]\n",
    "        df = df.drop(df[df['norm_text'].isin(self.stop_text)].index)\n",
    "        print('Deleted {} stop-texts from training corpus'.format(start_len-df.shape[0]))           \n",
    "\n",
    "        \n",
    "        ##############################################    \n",
    "        # Words in texts\n",
    "        word_list = []\n",
    "        for txt in self.text_src(df,'norm_text'):\n",
    "            for word in txt:\n",
    "                word_list.append(word)\n",
    "        word_df = pd.DataFrame(word_list, columns=['word'])\n",
    "        print('Found {} unique tokens in texts'.format(word_df['word'].nunique()))\n",
    "\n",
    "        # if 1==1:\n",
    "        #     top_n = 300\n",
    "        #     print('\\nTop {} most frequent tokens:'.format(top_n))\n",
    "        #     self.print_most_freq(word_df, 'word', top_n)\n",
    "\n",
    "        if 0==1:\n",
    "            top_n = 200\n",
    "            print('\\nTop {} rare tokens:\\n'.format(top_n))\n",
    "            self.print_most_freq(word_df, 'word', top_n, reverse=False)\n",
    "            \n",
    "        ##############################################    \n",
    "        # Add rare words to stop list\n",
    "        freq_word_dct = dict(word_df['word'].value_counts())\n",
    "        cnt = 0            \n",
    "        for w in freq_word_dct:\n",
    "            if freq_word_dct[w] == 1:\n",
    "                self.stop_words.append(w)\n",
    "                cnt += 1\n",
    "        print('{} rare words added to stop list'.format(cnt))\n",
    "\n",
    "        ##############################################    \n",
    "        # Remove stop words from norm texts, normalize text, iter 2\n",
    "        df['norm_text'] = df.apply(lambda row: ' '.join(self.normalize(row['text'])), axis=1)\n",
    "        print('Texts normalized again, stop-words removed from texts')\n",
    "        word_df  = self.calc_word_count(df, 'norm_text')\n",
    "        print('Now {} tokens in vocabulary'.format(self.word_count)) \n",
    "        \n",
    "        ##############################################    \n",
    "        # N-grams\n",
    "        # 2-grams\n",
    "        gram_df = self.generate_ngrams(df, 2, min_count=20, threshold=10)\n",
    "        print('\\n{} 2-grmas found'.format(gram_df['word'].nunique()))     \n",
    "        word_df  = self.calc_word_count(df, '2gram_text')\n",
    "        print('Now {} tokens in vocabulary'.format(self.word_count)) \n",
    "        if 0==1:\n",
    "            top_n = 100\n",
    "            print('\\nTop {} most frequent 2-grams:\\n'.format(top_n))\n",
    "            self.print_most_freq(gram_df, 'word', top_n)\n",
    "\n",
    "        if 1==1:\n",
    "            # 3-grams\n",
    "            gram_df = self.generate_ngrams(df, 3, min_count=10, threshold=30)\n",
    "            print('\\n{} 3-grmas found'.format(gram_df['word'].nunique()))         \n",
    "            word_df = self.calc_word_count(df, '3gram_text')\n",
    "            print('Now {} tokens in vocabulary'.format(self.word_count)) \n",
    "            if 0==1:\n",
    "                top_n = 50\n",
    "                print('\\nTop {} most frequent 3-grams:\\n'.format(top_n))\n",
    "                self.print_most_freq(gram_df, 'word', top_n)\n",
    "\n",
    "        if 0==1:\n",
    "            # 4-grams\n",
    "            gram_df = self.generate_ngrams(df, 4, min_count=7, threshold=40)\n",
    "            print('\\n{} 4-grmas found'.format(gram_df['word'].nunique()))         \n",
    "            word_df = self.calc_word_count(df, '4gram_text')\n",
    "            print('Now {} tokens in vocabulary'.format(self.word_count)) \n",
    "            if 1==1:\n",
    "                top_n = 10\n",
    "                print('\\nTop {} most frequent 4-grams:\\n'.format(top_n))\n",
    "                self.print_most_freq(gram_df, 'word', top_n)\n",
    "\n",
    "        \n",
    "        if 0==1:\n",
    "            # Show words in abc order\n",
    "            top_n = 2500\n",
    "            print('\\nTop {} most frequent words:'.format(top_n))\n",
    "            word_df = self.calc_word_count(df, '2gram_text')\n",
    "            word_dct = dict(word_df['word'])\n",
    "            words = []\n",
    "            for w in sorted(word_dct, key=word_dct.get, reverse=False):\n",
    "                if not word_dct[w] in words:\n",
    "                    words.append(word_dct[w])\n",
    "                    print(word_dct[w])\n",
    "                    top_n -= 1\n",
    "                    if not top_n:\n",
    "                        break    \n",
    "                        \n",
    "        ##############################################    \n",
    "        # Doc2vec\n",
    "        df['doc2vec_uid'] = range(1, len(df.index)+1)\n",
    "        train_corpus = list(self.text_src_to_tagged_docs(df, txt_column=self.train_column))\n",
    "        print('\\nPrepeared train corpus for Doc2vec, {} texts'.format(len(train_corpus)))\n",
    "        #print(train_corpus[500:800])\n",
    "        #[6.1, 300, 200, 2] [7.4, 50, 100, 2] [6.1, 250, 100, 2] [7.7, 100, 100, 2]\n",
    "        vector_size, epochs, window = 300, 200, 2\n",
    "        print('Creating model with hyperparameters: vector_sizes {} epochs {} window {} ...\\n'.format(vector_size, epochs, window))\n",
    "        self.vectorizer = gensim.models.doc2vec.Doc2Vec(train_corpus, vector_size=vector_size, window=window, min_count=1, workers=8, epochs=epochs)\n",
    "        print('Doc2vec model is ready, vocabulary {}'.format(len(self.vectorizer.wv.vocab)))\n",
    "        #pprint(self.vectorizer.wv.vocab)\n",
    "        \n",
    "        self.train_df = df\n",
    "        self.update_label_stat()\n",
    "\n",
    "dp = DataPipeline(data_folder='/home/od13/addons/tender_cat/data/model/dump/1', \n",
    "                  trained_folder='/home/od13/addons/tender_cat/data/model/trained/1')\n",
    "\n",
    "if 1==1:\n",
    "    dp.fit()\n",
    "\n",
    "if 1==1:\n",
    "    dp.save()\n",
    "\n",
    "\n",
    "\n",
    "dp = DataPipeline(data_folder='/home/od13/addons/tender_cat/data/model/dump/1', \n",
    "                  trained_folder='/home/od13/addons/tender_cat/data/model/trained/1')\n",
    "dp.load()\n",
    "tdf = dp.train_df\n",
    "\n",
    "\n",
    "sdf = tdf.groupby('label_id').nunique()\n",
    "pprint(sdf)\n",
    "\n",
    "def text_label(dp_self, txt, stack=20, sim_pow=3, debug=False):\n",
    "        \n",
    "        sims = dp_self.most_similar(txt, topn=stack)\n",
    "        \n",
    "        labels_cnt = {}\n",
    "        labels_sim = {}\n",
    "        \n",
    "        for sim in sims:\n",
    "            try:\n",
    "                label_id = sim['label_id'].iloc[0]\n",
    "            except:\n",
    "                continue\n",
    "                    \n",
    "            if label_id in labels_cnt: \n",
    "                labels_cnt[label_id] += 1 \n",
    "                labels_sim[label_id] += math.pow(sim['sim'], sim_pow)\n",
    "                #labels_sim[label_id] += sim['sim']*sim_pow\n",
    "            else:\n",
    "                labels_cnt[label_id] = 1 \n",
    "                labels_sim[label_id] = math.pow(sim['sim'], sim_pow)\n",
    "        \n",
    "        labels_score = {}\n",
    "        \n",
    "        for label_id in labels_cnt:\n",
    "            # Fraction of particular label set\n",
    "            norm_freq = labels_cnt[label_id]/dp_self.label_stat['norm_freq'][label_id]\n",
    "            \n",
    "            print('{} / {} = {}'.format(labels_cnt[label_id], dp_self.label_stat['norm_freq'][label_id], norm_freq))\n",
    "            \n",
    "            total_norm_freq = norm_freq #/self.label_stat['norm_freq'][label_id]\n",
    "            \n",
    "            # Look at similarity\n",
    "            #score = total_norm_freq*labels_sim[label_id]\n",
    "            #score = labels_cnt[label_id]*dp_self.label_stat['norm_freq'][label_id]* dp_self.label_stat['inverse_freq'][label_id]\n",
    "            score = (0.05*labels_cnt[label_id])*(labels_sim[label_id]/labels_cnt[label_id])*dp_self.label_stat['norm_freq'][label_id]*dp_self.label_stat['inverse_freq'][label_id]\n",
    "            \n",
    "            labels_score[label_id] = score\n",
    "            \n",
    "        sorted_labels = sorted(labels_score, key=labels_score.get, reverse=True)\n",
    "        if sorted_labels:\n",
    "            winner_id = sorted_labels[0]\n",
    "            vals = {\n",
    "                'label_id': winner_id,\n",
    "                'label_name': dp_self.label_stat['name'][winner_id],\n",
    "\n",
    "            }\n",
    "        else:\n",
    "            winner_id = 1001\n",
    "            vals = {\n",
    "                'label_id': winner_id,\n",
    "                'label_name': dp_self.label_stat['name'][winner_id],\n",
    "\n",
    "            }\n",
    "            \n",
    "        \n",
    "        if debug:\n",
    "            sims_name = {}\n",
    "            for w in sorted(labels_score, key=labels_score.get, reverse=True):\n",
    "                sims_name[dp_self.label_stat['name'][w]] = labels_score[w]\n",
    "            vals.update({\n",
    "                'sims': labels_score, \n",
    "                'sims_named': sims_name, \n",
    "                'sim':  labels_score[winner_id] if labels_score else 1,\n",
    "            })\n",
    "        \n",
    "        return vals\n",
    "\n",
    "label_freq, label_names, label_norm_freq, label_inverse_freq = {}, {}, {}, {}\n",
    "max_count, total_cnt, major_cnt = 0, 0, 0\n",
    "for i, row in tdf.groupby('label_id').nunique().iterrows():\n",
    "    cnt = row[dp.train_column]\n",
    "    label_freq[i] = cnt\n",
    "    total_cnt += cnt\n",
    "    if cnt > max_count:\n",
    "        max_count = cnt\n",
    "    if i==1001:\n",
    "        major_cnt += 1\n",
    "    label_names[i] = tdf.loc[tdf['label_id'] == i, 'label_name'].iloc[0]\n",
    "    # calc unique texts count instead\n",
    "    #print(max_count)\n",
    "\n",
    "major = total_cnt/(total_cnt - major_cnt)\n",
    "    \n",
    "for label_id in label_freq:\n",
    "    if label_id==1001:\n",
    "        label_norm_freq[label_id] = label_freq[label_id]/(max_count*major)\n",
    "    else:\n",
    "        label_norm_freq[label_id] = label_freq[label_id]/max_count\n",
    "    \n",
    "    label_inverse_freq[label_id] = math.log(1) + total_cnt/label_freq[label_id]\n",
    "\n",
    "dp.label_stat = {\n",
    "    'freq': label_freq,\n",
    "    'inverse_freq': label_inverse_freq,\n",
    "    'norm_freq': label_norm_freq,\n",
    "    'name': label_names,\n",
    "    'total_cnt': total_cnt,\n",
    "}\n",
    "\n",
    "pprint(dp.label_stat['inverse_freq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 0.9991204925241866 = 2.0017605633802815\n",
      "1 / 0.016908212560386472 = 59.142857142857146\n",
      "1 / 0.008454106280193236 = 118.28571428571429\n",
      "1 / 0.06642512077294686 = 15.054545454545453\n",
      "Winner: 1001 ?\n",
      "0.015212311243636466 ?\n",
      "0.0056771780140762755 Досвід виконання аналогічного договору\n",
      "0.005601879200456726 ПРОЕКТ ДОГОВІРУ\n",
      "0.005229772588199367 Кваліфікаційні довідки\n",
      "\n",
      "['цін', 'договір', 'зменшен', 'взаємн', 'згод', 'сторін']\n",
      "\n",
      "0.5117548704147339 -- ? -----------------------\n",
      "\n",
      "У випадку виникнення спорів або розбіжностей Сторони зобовязуються вирішувати їх шляхом взаємних переговорів та консультацій, пошуку взаємоприйнятних рішень, продовження строків врегулювання розбіжностей.\n",
      "\n",
      "випадк виникненн спор аб розбіжност сторон шлях взаємн переговор пошук рішен продовженн строк врегулюванн розбіжност\n",
      "\n",
      "0.4458391070365906 -- Досвід виконання аналогічного договору -----------------------\n",
      "\n",
      "Учаснику у складі тендерної пропозиції необхідно надати письмову згоду з істотними умовами договору, а також заповнений проєкт договору (Додаток №6 до тендерної документації) із додатками (кожна сторінка подається з власноручним підписом уповноваженої посадової особи учасника процедури закупівлі, а також з відбитком печатки (за наявності)).\n",
      "\n",
      "склад тендерн пропозиці необхідн письмов згод істотн умов договір заповнен проєкт договір додаток №6 тендерн документаці додатк кожн сторінк подаєт власноручн посадово процедур_закупівл відбитк наявност\n",
      "\n",
      "0.4444631338119507 -- ПРОЕКТ ДОГОВІРУ -----------------------\n",
      "\n",
      "Учаснику у складі тендерної пропозиції необхідно надати письмову згоду з істотними умовами договору, а також заповнений проєкт договору (Додаток №6 до тендерної документації) із додатками (кожна сторінка подається з власноручним підписом уповноваженої посадової особи учасника процедури закупівлі, а також з відбитком печатки (за наявності)).\n",
      "\n",
      "склад тендерн пропозиці необхідн письмов згод істотн умов договір заповнен проєкт договір додаток №6 тендерн документаці додатк кожн сторінк подаєт власноручн посадово процедур_закупівл відбитк наявност\n",
      "\n",
      "0.4254363179206848 -- ? -----------------------\n",
      "\n",
      "Додаток тендерної документації: «Проект договору.\n",
      "\n",
      "додаток тендерн документаці проект договір\n",
      "\n",
      "0.42178624868392944 -- ? -----------------------\n",
      "\n",
      "Перерахунок ціни тендерних пропозицій учасника - нерезидента з іноземної валюти в гривні здійснюється шляхом помноження ціни пропозиції цього учасника у валюті І групи на офіціальний курс НБУ до такої валюти станом на дату розкриття тендерних пропозицій.\n",
      "\n",
      "перерахунок цін тендерн пропозиці нерезидент іноземно валют гривн здіиснюєт шлях помноженн цін пропозиці валют груп офіціальн курс нбу тако валют стан розкритт тендерн пропозиці\n",
      "\n",
      "0.41826754808425903 -- Кваліфікаційні довідки -----------------------\n",
      "\n",
      "Лист підтвердження згоди з проектом договору:\n",
      "\n",
      "лист підтвердженн згод проект договір\n",
      "\n",
      "0.4151122570037842 -- ? -----------------------\n",
      "\n",
      "РЕКВІЗИТИ СТОРІН.\n",
      "\n",
      "реквізит сторін\n",
      "\n",
      "0.41457217931747437 -- ? -----------------------\n",
      "\n",
      "Перерахунок ціни тендерних пропозицій учасника - нерезидента з іноземної валюти в гривні здійснюється шляхом помноження ціни пропозиції цього учасника у валюті І групи на офіціальний курс НБУ до такої валюти станом на дату розкриття тендерних пропозицій.\n",
      "\n",
      "перерахунок цін тендерн пропозиці нерезидент іноземно валют гривн здіиснюєт шлях помноженн цін пропозиці валют груп офіціальн курс нбу тако валют стан розкритт тендерн пропозиці\n",
      "\n",
      "0.39914119243621826 -- ? -----------------------\n",
      "\n",
      "Даний протокол є підставою для проведення взаємних розрахунків платежів між Підрядником і Замовником.\n",
      "\n",
      "дан протокол підстав проведенн взаємн розрахунк платеж між підрядник замовник\n",
      "\n",
      "0.39830049872398376 -- Кошторис -----------------------\n",
      "\n",
      "Визначальним буде вважатися друкований варіант розрахунку ціни тендерної пропозиції.\n",
      "\n",
      "визначальн буд вваж розрахунк цін тендерн пропозиці\n",
      "\n",
      "0.3894566297531128 -- ? -----------------------\n",
      "\n",
      "Ціна без ПДВ:, грн.:\n",
      "\n",
      "цін пдв грн.\n",
      "\n",
      "0.3882780075073242 -- ? -----------------------\n",
      "\n",
      "Даний протокол є невідємною частиною договору №від 2020 р.\n",
      "\n",
      "дан протокол невідємн частин договір №від\n",
      "\n",
      "0.38615652918815613 -- ? -----------------------\n",
      "\n",
      "Сторона договору, яка одержала пропозицію про внесення змін у договір підряду або розірвання його, у десятиденний строк повідомляє другу сторону про своє рішення.\n",
      "\n",
      "сторон договір пропозиц внесенн змін договір підряд аб розірванн строк повідомля друг сторон рішенн\n",
      "\n",
      "0.3822804391384125 -- ? -----------------------\n",
      "\n",
      "Ми, що підписалися нижче, від імені Замовника, в особі заступника начальника управління Лапіка О.В., що діє на підставі Положення про управління та від імені Підрядника, в особі ., який діє на підставі , засвідчуємо, що сторонами досягнуто згоди про розмір договірної ціни на виконання робіт п.обєкту: «Капітальний ремонт житлового будинку №14 п.вул.\n",
      "\n",
      "ми нижч імен замовник заступник начальник управлінн лапік о.в. ді підстав положенн управлінн імен підрядник ді підстав сторон згод розмір договірно цін виконанн_робіт п.обєкт капітальн ремонт житлов будинк №14 п.вул\n",
      "\n",
      "0.38108158111572266 -- ? -----------------------\n",
      "\n",
      "У випадку обґрунтованої необхідност.строк для укладання договору може бути продовжений до 60 днів.\n",
      "\n",
      "випадк обґрунтовано необхідност.строк укладанн договір продовжен 60 днів\n",
      "\n",
      "0.38027137517929077 -- ? -----------------------\n",
      "\n",
      "У випадку обґрунтованої необхідност.строк для укладання договору може бути продовжений до 60 днів.\n",
      "\n",
      "випадк обґрунтовано необхідност.строк укладанн договір продовжен 60 днів\n",
      "\n",
      "0.37882447242736816 -- ? -----------------------\n",
      "\n",
      "Сторона договору підряду, яка вважає за необхідне внест.зміни у договір підряду ч.розірвати його, повинна надіслати відповідну пропозицію другій стороні.\n",
      "\n",
      "сторон договір підряд вваж необхідн внест.змін договір підряд повинн відповідн пропозиц другі сторон\n",
      "\n",
      "0.3781372606754303 -- ? -----------------------\n",
      "\n",
      "ВІДПОВІДАЛЬНІСТЬ СТОРІН ЗА ПОРУШЕННЯ УМОВ ДОГОВОРУ\n",
      "\n",
      "відповідальн сторін порушенн договір\n",
      "\n",
      "0.37699300050735474 -- ? -----------------------\n",
      "\n",
      "Ціна без ПДВ:, грн.:\n",
      "\n",
      "цін пдв грн.\n",
      "\n",
      "0.3740912675857544 -- ? -----------------------\n",
      "\n",
      "У випадку обґрунтованої необхідност.строк для укладання договору може бути продовжений до 60 днів.\n",
      "\n",
      "випадк обґрунтовано необхідност.строк укладанн договір продовжен 60 днів\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test_sent = 'Копія свідоцтва про реєстрацію платника ПДВ або витягу з реєстру платників ПДВ або копія свідоцтва сплати єдиного податку або копія витягу з реєстру платників єдиного податку'\n",
    "#test_sent = 'У разі якщо учасник, відповідно до норм чинного законодавства не є платником податку на додану вартість або єдиного податку, такий учасник подає довідку в довільній формі із зазначенням системи оподаткування, яку він обрав, подає підтверджуючі документи (у разі наявності) та зазначає інформацію про законодавчі підстави для їх ведення.'\n",
    "#test_sent = 'Довідка у довільній формі про досвід виконання аналогічного (них) договору (ів) за 2020, що відповідають'\n",
    "#test_sent = 'В разі отримання мотивованої відмови Замовника від підписання Акту виконаних робіт (наданих послуг) Сторонами складається протокол, в якому вказуються зауваження і терміни їх усунення, обов\\'язкові для Виконавця.'\n",
    "#test_sent = 'Довідка у вигляді електронного документу із ЕЦП КЕП особи, яка уповноважена на підписання такої довідки або сканкопія папурової  довідки або сканкопія нотаріально завіреної довідки про те, що службова (посадова) особа переможця процедури закупівлі, яка підписала тендерну пропозицію, не знятої чи не погашеної судимості  не має.'\n",
    "#test_sent = 'Погоджений учасником проект договору згідно Додатку 3 Оголошення.'\n",
    "#test_sent = 'Інформація в довільній формі за власноручним підписом фізичної особи, яка є учасником та завірена печаткою (у разі наявності) про те, що фізична особа, яка є учасником, не була засуджена за злочин, учинений з корисливих мотивів (зокрема, повязаний з хабарництвом та відмиванням коштів), судимість з якої не знято або не погашено у встановленому законом порядку'\n",
    "#test_sent = 'довідку про вжиття заходів із захисту довкілля під час надання послуг згідно предмету закупівлі'\n",
    "#test_sent = 'копії Статуту або іншого установчого документу (зі змінами), за підписом уповноваженої особи учасника та печаткою (за наявності).'\n",
    "#test_sent = 'Вимоги до статуту - статут повинен містити відмітку державного реєстратора про проведення державної реєстрації (у випадку відсутност.відмітки державного реєстратора Учасник повинен надати інформацію з кодом доступу до результатів надання адміністративних послуг у сфері державної реєстрації, за яким існує можливіст.переглянути електронну версію документу (ів))'\n",
    "#test_sent = '- довідки про присвоєння-ідентифікаційного коду (для фізичних осіб), за підписом уповноваженої особи учасника.'\n",
    "#test_sent = '- листа-згоди уповноваженої (посадової) особи (осіб) учасника, що підписала документи тендерної пропозиції, який підтверджує дозвіл на використання, розповсюдження і доступ до персональних даних згідно з нормами законодавства України (у довільній формі)'\n",
    "#test_sent = 'Повноваження щодо підпису документів тендерної пропозиції уповноваженої особи учасника процедури закупівлі підтверджується: для посадових (службових) осіб учасника, які уповноважені підписувати документи пропозиції та вчиняти інші юридично значущі дії від імені учасника на підставі положень установчих документів – розпорядчий документ про призначення (обрання) на посаду відповідної особи (наказ про призначення та  або протокол зборів засновників, тощо), з наданням копії паспорту уповноваженої особи; для осіб, що уповноважені представляти інтереси учасника під час проведення процедури закупівлі, та які не входять до кола осіб, що представляють інтереси учасника без довіреност.– довіреність, оформлена у відповідност.до вимог чинного законодавства, із зазначенням повноважень повіреного, разом з документами, що у відповідност.до цього пункту підтверджують повноваження посадової (службової) особи учасника, що підписала від імені учасника вказану довіреність.'\n",
    "#test_sent = 'Умови, форма та зміст банківської гарантії повинні відповідати вимогам Положення про порядок здійснення банками операцій за гарантіями в національній та іноземних валютах, затвердженим Постановою Правління Національного банку України від 15.12.2004 №639, та містити наступні реквізити умови:'\n",
    "#test_sent = 'Вимога щодо засвідчення того чи іншого документу тендерної пропозиції власноручним підписом учасника уповноваженої не застосовується до документів (матеріалів та інформації), що подаються у складі тендерної пропозиції, якщо такі документи (матеріали та інформація) надані учасником у формі електронного документа через електронну систему закупівель із накладанням кваліфікованого електронного підпису на кожен з таких документів (матеріал чи інформацію).'\n",
    "#test_sent = 'інформації та документів, що підтверджують відповідність учасника кваліфікаційним критеріям;'\n",
    "#test_sent = 'Підпис керівника або уповноваженої особи Учасника - юридичної особи, фізичної особи – підприємця'\n",
    "\n",
    "#test_sent = 'г) система оподаткування;'\n",
    "#test_sent = 'Інформація про відсутність підстави, надається в довільній формі за підписом уповноваженої особи учасника та завірену печаткою (у разі використання)'\n",
    "#test_sent = '2) наявність працівників відповідної кваліфікації, які мають необхідні знання та досвід;'\n",
    "#test_sent = 'Протокол №51 від 10.10.2020 р.'\n",
    "#test_sent = '- не розливу нафтопродуктів, мастил та інших хімічних речовин на грунт, асфальтове покриття;'\n",
    "#test_sent = '- під час експлуатації автотранспорту викид відпрацьованих газів не повинен перевищувати допустимі норми;'\n",
    "#test_sent = '2) наявність працівників відповідної кваліфікації, які мають необхідні знання та досвід;'\n",
    "#test_sent = 'Ініціювати внесення змін у Договір підряду, вимагати розірвання Договору підряду та відшкодування збитків за наявності істотних порушень «Підрядником» умов Договору підряду.'\n",
    "test_sent = 'Ціна цього Договору може бути зменшена за взаємною згодою Сторін.'\n",
    "#est_sent = 'Інші умови'\n",
    "#test_sent = 'Умовами цієї документації не встановлено поділ предмета закупівлі на окремі частини (лоти).'\n",
    "#test_sent = 'Замовник протягом одного робочого дня з дня їх оприлюднення зобовязаний надати розяснення на звернення учасників спрощеної закупівлі, які оприлюднюються в електронній системі закупівель, та або внести зміни до оголошення про проведення спрощеної закупівлі, та або вимог до предмета закупівлі'\n",
    "#test_sent = 'Пропозиція подається в електронному вигляді шляхом заповнення електронних форм з окремими полями, у яких зазначається інформація про ціну, інші критерії оцінки (у разі їх установлення замовником), та завантаження файлів з:'\n",
    "#test_sent = 'Заходи щодо захисту довкілля, які повинні бути обєднані в інформативну довідку:'\n",
    "\n",
    "#test_sent = 'Повідомлення про відміну закупівлі автоматично надсилається всім учасникам електронною системою закупівель в день його оприлюднення.'\n",
    "#test_sent = '8) зміни умов у звязку із застосуванням положень частини шостої статті 41 Закону.'\n",
    "#test_sent = 'Пропозиція подається в електронному вигляді шляхом заповнення електронних форм з окремими полями, у яких зазначається інформація про ціну, інші критерії оцінки (у разі їх установлення замовником), та завантаження файлів з:'\n",
    "#test_sent = 'Ціна пропозиції учасника (договірна ціна) - сума за яку учасник пропонує виконати перелік робіт, передбачених в технічній частині документації.'\n",
    "#test_sent = '1) пропозиція учасника не відповідає умовам, визначеним в оголошенні про проведення спрощеної закупівлі, та вимогам до предмета закупівлі;'\n",
    "\n",
    "if 1==1:        \n",
    "    #sim = dp.text_label(test_sent, stack=20, sim_pow=3, debug=True)\n",
    "    sim = text_label(dp, test_sent, stack=5, sim_pow=3, debug=True)\n",
    "\n",
    "    print('Winner: {} {}'.format(sim['label_id'], sim['label_name']))\n",
    "    sim_names = sim['sims_named']\n",
    "    for w in sorted(sim_names, key=sim_names.get, reverse=True):\n",
    "        print('{} {}'.format(sim_names[w], w))\n",
    "\n",
    "    print('\\n{}\\n'.format(dp.normalize(test_sent)))\n",
    "\n",
    "    sims = dp.most_similar(test_sent, topn=20)\n",
    "\n",
    "    for sim in sims:\n",
    "        try:\n",
    "            print('{} -- {} -----------------------\\n'.format(sim['sim'], sim['label_name'].iloc[0]))\n",
    "            print('{}\\n'.format(sim['text'].iloc[0]))\n",
    "            print('{}\\n'.format(sim['train_text'].iloc[0]))\n",
    "        except:\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 656 sentences, 1 files\n",
      "Character counts in texts: min 2, max 1619,  mean 146.6859756097561\n",
      "\n",
      "Deleted 1 long texts\n",
      "Deleted 2 short texts\n",
      "Deleted 26 stop-texts from training corpus\n",
      "Found 848 unique tokens in texts\n",
      "1 rare words added to stop list\n",
      "Start classifier\n",
      "Labeled 334 sentences with 23 labels\n",
      "CPU times: user 1min 30s, sys: 3min 40s, total: 5min 11s\n",
      "Wall time: 39.8 s\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "def transform(dp_self, input_file=None, output_file=None, trained_folder=None, a=None):\n",
    "\n",
    "    # Load input csv file\n",
    "    df = pd.read_csv(input_file)\n",
    "    df.fillna(value={'label_id': 1001, 'label_name': '?'}, inplace=True)\n",
    "    print('Loaded {} sentences, {} files'.format(df.shape[0], len(set(df['file'].dropna()))))\n",
    "    \n",
    "    ################################################\n",
    "    # Characters count\n",
    "    df['chr_count'] = df.apply(lambda row: len(row['text']), axis=1)\n",
    "\n",
    "    stat = {'chr_count_max': df['chr_count'].max(), 'chr_count_min': df['chr_count'].min() }\n",
    "\n",
    "    print('Character counts in texts: min {}, max {},  mean {}\\n'.format(stat['chr_count_min'], stat['chr_count_max'], df['chr_count'].mean()))\n",
    "\n",
    "    ################################################\n",
    "    # Delete too long sentences, max chr count -1\n",
    "    start_len = df.shape[0]\n",
    "    df = df.drop(df[df.chr_count >= stat['chr_count_max']-1].index)\n",
    "    print('Deleted {} long texts'.format(start_len-df.shape[0]))\n",
    "\n",
    "    if 0==1:\n",
    "        top_n = 5\n",
    "        print('\\nTop {} most long now: '.format(top_n))\n",
    "        print(df.sort_values('chr_count', ascending = False)['text'].head(top_n))\n",
    "\n",
    "    ################################################\n",
    "    # Delete too short sentences, chr count == min\n",
    "    start_len = df.shape[0]\n",
    "    max_chr_count = max(3, stat['chr_count_min'])\n",
    "    df = df.drop(df[df.chr_count <= max_chr_count].index)\n",
    "    print('Deleted {} short texts'.format(start_len-df.shape[0]))\n",
    "\n",
    "    if 0==1:\n",
    "        top_n = df.shape[0]//50\n",
    "        print('\\nTop {} most short now: '.format(top_n))\n",
    "        print(df.sort_values('chr_count', ascending = True)['text'].head(top_n))\n",
    "            \n",
    "    ##############################################    \n",
    "    # Generate normalized text, iter 1\n",
    "    df['norm_text'] = df.apply(lambda row: str(' '.join(dp_self.normalize(row['text'])).strip()), axis=1)\n",
    "        \n",
    "    # We may unload most frequent texts to disk here\n",
    "        \n",
    "    ##############################################    \n",
    "    # Delete stop_texts\n",
    "    start_len = df.shape[0]\n",
    "    df = df.drop(df[df['norm_text'].isin(dp_self.stop_text)].index)\n",
    "    print('Deleted {} stop-texts from training corpus'.format(start_len-df.shape[0]))           \n",
    "\n",
    "        \n",
    "    ##############################################    \n",
    "    # Words in texts\n",
    "    word_list = []\n",
    "    for txt in dp_self.text_src(df,'norm_text'):\n",
    "        for word in txt:\n",
    "            word_list.append(word)\n",
    "    word_df = pd.DataFrame(word_list, columns=['word'])\n",
    "    print('Found {} unique tokens in texts'.format(word_df['word'].nunique()))\n",
    "\n",
    "    if 0==1:\n",
    "        top_n = 300\n",
    "        print('\\nTop {} most frequent tokens:'.format(top_n))\n",
    "        dp_self.print_most_freq(word_df, 'word', top_n)\n",
    "\n",
    "    if 0==1:\n",
    "        top_n = 200\n",
    "        print('\\nTop {} rare tokens:\\n'.format(top_n))\n",
    "        dp_self.print_most_freq(word_df, 'word', top_n, reverse=False)\n",
    "            \n",
    "    ##############################################    \n",
    "    # Add rare words to stop list\n",
    "    freq_word_dct = dict(word_df['word'].value_counts())\n",
    "    cnt = 0            \n",
    "    for w in freq_word_dct:\n",
    "        if freq_word_dct[w] == 1:\n",
    "            dp_self.stop_words.append(w)\n",
    "            cnt += 1\n",
    "    print('{} rare words added to stop list'.format(cnt))\n",
    "\n",
    "    ##############################################    \n",
    "    # Remove stop words from norm texts, normalize text, iter 2\n",
    "    if 1==1:\n",
    "        df['norm_text'] = df.apply(lambda row: ' '.join(dp_self.normalize(row['text'])), axis=1)\n",
    "        print('Texts normalized again, stop-words removed from texts')\n",
    "        word_df  = dp_self.calc_word_count(df, 'norm_text')\n",
    "        print('Now {} tokens in vocabulary'.format(dp_self.word_count)) \n",
    "    \n",
    "    \n",
    "    \n",
    "    with open(output_file, mode='w') as file:\n",
    "        csv_fields = ['label_id', 'label_name', 'text', 'text_id', 'file', 'tender']\n",
    "        writer = csv.DictWriter(file, fieldnames=csv_fields, delimiter=',')\n",
    "        writer.writeheader()\n",
    "        print('Start classifier')\n",
    "        label_cnt = 0\n",
    "        label_set = set()\n",
    "        topn = 20000\n",
    "\n",
    "        for i, row in df.iterrows(): \n",
    "            text = row['norm_text']\n",
    "            if not isinstance(text, str):\n",
    "                continue\n",
    "                \n",
    "            sim = dp.text_label(text, stack=20, sim_pow=2, debug=False)\n",
    "            \n",
    "            if 0==1:\n",
    "                print('\\n------------------')\n",
    "                print('{}'.format(text))\n",
    "                print('{}\\n'.format(dp.normalize(text)))\n",
    "\n",
    "                print('Winner: {} {}'.format(sim['label_id'], sim['label_name']))\n",
    "                sim_names = sim['sims_named']\n",
    "                for w in sorted(sim_names, key=sim_names.get, reverse=True):\n",
    "                    print('{} {}'.format(sim_names[w], w))\n",
    "            \n",
    "            \n",
    "            label_id = sim['label_id']\n",
    "            label_name = sim['label_name']\n",
    "            \n",
    "            if not label_name == '?':\n",
    "                label_cnt += 1\n",
    "                label_set.add(label_name)\n",
    "\n",
    "            val = {'label_id': '' if label_name == '?' else label_id,\n",
    "                   'label_name': '' if label_name == '?' else label_name,\n",
    "                   'text': text,\n",
    "                   'text_id': df['text_id'][i],\n",
    "                   }\n",
    "            writer.writerow(val)\n",
    "            \n",
    "            topn -= 1\n",
    "            if topn == 0:\n",
    "                break\n",
    "\n",
    "        print('Labeled {} sentences with {} labels'.format(label_cnt, len(label_set)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "%time transform(dp, input_file='/home/od13/addons/tender_cat/data/model/run/1/29input.csv', output_file='/home/od13/addons/tender_cat/data/model/run/1/29output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (tender_cat)",
   "language": "python",
   "name": "pycharm-59b3698e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}