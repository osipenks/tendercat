{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sentence classifier, model deployment \n",
    "Load data from model dump folder, train and store for further use in production\n",
    "### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10037 sentences from 36 files\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, unidecode, random, gensim, logging\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "sys.path.append('/home/od13/addons/tender_cat/libcat/mytextpipe/')\n",
    "from mytextpipe import corpus\n",
    "from uk_stemmer import UkStemmer\n",
    "from string import punctuation \n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "_logger = logging.getLogger(__name__)\n",
    "\n",
    "path = '/home/od13/addons/tender_cat/data/model/dump/3'\n",
    "\n",
    "csvs = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for f in files: \n",
    "        if f.endswith(\".csv\"):\n",
    "            try: \n",
    "                csv = pd.read_csv(os.path.join(path, f))\n",
    "                csvs.append(csv)\n",
    "            except (FileExistsError, IOError, pd.errors.EmptyDataError) as e:\n",
    "                _logger.error('{}: {}'.format(f,e))\n",
    "\n",
    "txt_data = pd.concat(csvs,ignore_index=True)\n",
    "txt_data.fillna(value = {'label_id': 0, 'label_name': '?'}, inplace=True)\n",
    "#todo: check columns, missing and duplicated\n",
    "\n",
    "print('Loaded {} sentences from {} files'.format(txt_data.shape[0], len(set(txt_data['file'].dropna()))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepeared train corpus for doc2vec, items count 10033\n"
     ]
    }
   ],
   "source": [
    "corp = corpus.HTMLCorpusReader('.', stemmer=UkStemmer(), clean_text=True, language='russian')\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    url_pattern = r'https?://\\S+|http?://\\S+|www\\.\\S+'\n",
    "    text = re.sub(pattern=url_pattern, repl=' ', string=text)\n",
    "    \n",
    "    #text = unidecode.unidecode(text)\n",
    "    text = text.translate(str.maketrans('', '', punctuation))\n",
    "    \n",
    "    number_pattern = r'\\d+'\n",
    "    #text = re.sub(pattern=number_pattern, repl=\"nmbr\", string=text)\n",
    "    #text = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
    "    \n",
    "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
    "    text = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
    "    \n",
    "    text = gensim.utils.decode_htmlentities(gensim.utils.deaccent(text))\n",
    "    \n",
    "    space_pattern = r'\\s+'\n",
    "    text = re.sub(pattern=space_pattern, repl=\" \", string=text)\n",
    "    \n",
    "    return [x for x in corp.text_to_words(text)]\n",
    "\n",
    "def read_corpus_df(source_df, tokens_only=False, txt_column='text'):\n",
    "    for index, row in source_df.iterrows():\n",
    "        word_lst = normalize(str(row[txt_column]))\n",
    "        if word_lst:\n",
    "            if tokens_only:\n",
    "                yield word_lst\n",
    "            else:\n",
    "                yield gensim.models.doc2vec.TaggedDocument(word_lst, [row['doc2vec_uid']])\n",
    "\n",
    "def ivec(word_list, model, epochs=850, alpha=0.025):\n",
    "    return model.infer_vector(word_list, epochs=epochs)\n",
    "\n",
    "def map_label(labels, name=None, index=None):\n",
    "    if name is not None:\n",
    "        return labels[name]\n",
    "    elif index is not None:\n",
    "        return list(labels.keys())[list(labels.values()).index(index)]\n",
    "    else:\n",
    "        raise ValueError(\"Specify name or number, not both\")\n",
    "\n",
    "label_dct = {}\n",
    "for i, val in enumerate(list(set(txt_data['label_name'].dropna()))):\n",
    "    label_dct.update({val: i})\n",
    "       \n",
    "txt_data['doc2vec_uid'] = range(1, len(txt_data.index)+1)\n",
    "train_corpus = list(read_corpus_df(txt_data))\n",
    "\n",
    "print('Prepeared train corpus for doc2vec, items count {}'.format(len(train_corpus)))\n",
    "#pprint(train_corpus[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantinate doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with hyperparameters: vector_sizes 300 epochs 200 window 2 ...\n",
      "CPU times: user 6min 4s, sys: 1min 17s, total: 7min 21s\n",
      "Wall time: 4min 21s\n",
      "\n",
      "Doc2vec model is ready, vocabulary 7130\n"
     ]
    }
   ],
   "source": [
    "val_results = [7.4, 50, 100, 2] #[6.1, 250, 100, 2] [7.7, 100, 100, 2]\n",
    "val_results = [6.1, 250, 100, 2]\n",
    "val_results = [7.7, 100, 100, 2]\n",
    "val_results = [6.1, 300, 200, 2]\n",
    "\n",
    "print('Creating model with hyperparameters: vector_sizes {} epochs {} window {} ...'.format(val_results[1], val_results[2], val_results[3]))\n",
    "%time model = gensim.models.doc2vec.Doc2Vec(train_corpus, vector_size=val_results[1], window=val_results[3], min_count=1, workers=8, epochs=val_results[2])\n",
    "print('\\nDoc2vec model is ready, vocabulary {}'.format(len(model.wv.vocab)))\n",
    "#pprint(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test doc2vec model\n",
    "Rank by similarities, cross validate with other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = 'У разі якщо учасник, відповідно до норм чинного законодавства не є платником податку на додану вартість або єдиного податку, такий учасник подає довідку в довільній формі із зазначенням системи оподаткування, яку він обрав, подає підтверджуючі документи (у разі наявності) та зазначає інформацію про законодавчі підстави для їх ведення.'\n",
    "test_sent = 'Довідка у довільній формі про досвід виконання аналогічного (них) договору (ів) за 2020 рік, що відповідають предмету закупівлі (в разі укладання подібних договорів).'\n",
    "#test_sent = 'В разі отримання мотивованої відмови Замовника від підписання Акту виконаних робіт (наданих послуг) Сторонами складається протокол, в якому вказуються зауваження і терміни їх усунення, обов\\'язкові для Виконавця.'\n",
    "#test_sent = 'Довідка у вигляді електронного документу із ЕЦП КЕП особи, яка уповноважена на підписання такої довідки або сканкопія папурової  довідки або сканкопія нотаріально завіреної довідки про те, що службова (посадова) особа переможця процедури закупівлі, яка підписала тендерну пропозицію, не знятої чи не погашеної судимості  не має.'\n",
    "#test_sent = 'Погоджений учасником проект договору згідно Додатку 3 Оголошення.'\n",
    "#test_sent = 'Інформація в довільній формі за власноручним підписом фізичної особи, яка є учасником та завірена печаткою (у разі наявності) про те, що фізична особа, яка є учасником, не була засуджена за злочин, учинений з корисливих мотивів (зокрема, повязаний з хабарництвом та відмиванням коштів), судимість з якої не знято або не погашено у встановленому законом порядку'\n",
    "#test_sent = 'Копія свідоцтва про реєстрацію платника ПДВ або витягу з реєстру платників ПДВ або копія свідоцтва сплати єдиного податку або копія витягу з реєстру платників єдиного податку'\n",
    "\n",
    "inferred_vector = ivec(normalize(test_sent), model)\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=10)\n",
    "\n",
    "found_rows = txt_data['doc2vec_uid'].isin([doc_id for doc_id, sim in sims])\n",
    "#for index, row in txt_data[found_rows].iterrows():\n",
    "#    print(sim, row['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset 1957, train 1761, test 196 sentences\n",
      "Start classifier training...\n",
      "CPU times: user 3min 4s, sys: 3min 34s, total: 6min 38s\n",
      "Wall time: 50.2 s\n",
      "Labels in tests 196\n",
      "Accuracy 0.8928571428571429\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "              Ліцензії або дозвільні документи       0.00      0.00      0.00         0\n",
      "          Наявність матеріально-технічної бази       1.00      1.00      1.00         2\n",
      "                           Підтвердження особи       1.00      1.00      1.00         1\n",
      "                           Фінансова звітність       1.00      1.00      1.00         1\n",
      "                                Персональн дан       0.00      0.00      0.00         0\n",
      "                            Кошторис imd(файл)       0.00      0.00      0.00         0\n",
      "                               ПРОЕКТ ДОГОВІРУ       0.50      1.00      0.67         1\n",
      "                           Установчі документи       0.00      0.00      0.00         2\n",
      "                      Календарний графік робіт       0.00      0.00      0.00         0\n",
      "                           Банківська гарантія       1.00      0.67      0.80         3\n",
      "                                Акт обстеження       0.00      0.00      0.00         0\n",
      "                             Цінова пропозиція       0.00      0.00      0.00         1\n",
      "                       Статус платника податку       1.00      0.50      0.67         2\n",
      "                               Технічні вимоги       0.00      0.00      0.00         1\n",
      "                                             ?       0.94      0.97      0.96       168\n",
      "                          Повноваження підпису       0.00      0.00      0.00         0\n",
      "                  Накладання печаті та підпису       0.00      0.00      0.00         0\n",
      "                           Накладання ЕЦП(КЕП)       0.00      0.00      0.00         0\n",
      "Наявність працівників відповідної кваліфікації       0.00      0.00      0.00         1\n",
      "             Довідка про відсутність судимості       0.00      0.00      0.00         2\n",
      "                                      Кошторис       1.00      0.25      0.40         4\n",
      "                          Довідка по статті 17       0.25      0.67      0.36         3\n",
      "                Довідка з обслуговуючого банку       0.00      0.00      0.00         0\n",
      "        Досвід виконання аналогічного договору       0.00      0.00      0.00         0\n",
      "                        Кваліфікаційні довідки       0.50      0.25      0.33         4\n",
      "\n",
      "                                     micro avg       0.89      0.89      0.89       196\n",
      "                                     macro avg       0.33      0.29      0.29       196\n",
      "                                  weighted avg       0.89      0.89      0.88       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "txt_data['cls_uid'] = [-1 for i in range(1, len(txt_data.index)+1)]\n",
    "\n",
    "X,y,cnt = [],[],0\n",
    "for index, row in txt_data.iterrows():\n",
    "    vec_uid = row['doc2vec_uid']\n",
    "    if vec_uid in model.docvecs:\n",
    "        text_vec = model.docvecs[vec_uid]\n",
    "        X.append(text_vec)\n",
    "        y.append(map_label(label_dct, name=row['label_name']))\n",
    "        row['cls_uid'] = cnt\n",
    "        cnt += 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1)\n",
    "\n",
    "print('Full dataset {}, train {}, test {} sentences'.format(len(y), len(y_train), len(y_test)))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "print('Start classifier training...')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "# activation = {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}\n",
    "# solver = {‘lbfgs’, ‘sgd’, ‘adam’}\n",
    "# max_iter = 200\n",
    "# learning_rate = {‘constant’, ‘invscaling’, ‘adaptive’}\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-7, hidden_layer_sizes=(200, 100), random_state=1, activation='logistic', max_iter = 2000,\n",
    "                    learning_rate = 'adaptive', verbose=False, tol=1e-6)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#clf = SVC(C=2.0, kernel='poly', degree=5, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.0001, \n",
    "#          cache_size=800, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=1)\n",
    "\n",
    "%time y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "doc_cnt = sum([1 for lab in y_test if lab != 0])\n",
    "print('Labels in tests {}'.format(doc_cnt))\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred, zero_division=0,\n",
    "                            target_names = list([map_label(label_dct, index=i) for i in range(0, len(label_dct))]),\n",
    "                            labels=list([map_label(label_dct, name=map_label(label_dct, index=i)) for i in range(0, len(label_dct))])\n",
    "     ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec model saved to /home/od13/addons/tender_cat/data/model/trained/vectorizer.mod\n",
      "classifier saved to /home/od13/addons/tender_cat/data/model/trained/classifier.mod\n"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "trained_folder = '/home/od13/addons/tender_cat/data/model/trained'\n",
    "if not os.path.exists(trained_folder):\n",
    "    raise FileNotFoundError('Trained model folder {} not found'.format(trained_folder))\n",
    "\n",
    "vec_path = os.path.join(trained_folder, 'vectorizer.mod')\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "joblib.dump(model, vec_path)\n",
    "print('doc2vec model saved to {}'.format(vec_path))\n",
    "\n",
    "clf_path = os.path.join(trained_folder, 'classifier.mod')\n",
    "joblib.dump(clf, clf_path) \n",
    "print('classifier saved to {}'.format(clf_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 95/1956 [00:05<01:55, 16.11it/s, docs found 10 of total 15, false items 5=66.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found sentences about documents 10 from total 15\n",
      "---- (pred) Кваліфікаційні довідки (real) ?:\n",
      "Місцезнаходження (адреса)\n",
      "---- (pred) Технічні вимоги (real) ?:\n",
      "Інформація про предмет закупівлі:\n",
      "---- (pred) Цінова пропозиція (real) ?:\n",
      "Інформація про мову (мови), якою (якими) повинно бути складено тендерні пропозиції\n",
      "---- (pred) Цінова пропозиція (real) ?:\n",
      "Унесення змін до тендерної документації.\n",
      "---- (pred) Довідка по статті 17 (real) Кваліфікаційні довідки:\n",
      "'- інформації та документів, що підтверджують відповідніст.учасника кваліфікаційним критеріям;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#test_sent = 'Довідка у довільній формі про досвід виконання аналогічного (них) договору (ів) за 2020 рік, що відповідають предмету закупівлі (в разі укладання подібних договорів).'\n",
    "#test_sent = 'В разі отримання мотивованої відмови Замовника від підписання Акту виконаних робіт (наданих послуг) Сторонами складається протокол, в якому вказуються зауваження і терміни їх усунення, обов\\'язкові для Виконавця.'\n",
    "#test_sent = 'Довідка у вигляді електронного документу із ЕЦП КЕП особи, яка уповноважена на підписання такої довідки або сканкопія папурової  довідки або сканкопія нотаріально завіреної довідки про те, що службова (посадова) особа переможця процедури закупівлі, яка підписала тендерну пропозицію, не знятої чи не погашеної судимості  не має.'\n",
    "#test_sent = 'Погоджений учасником проект договору згідно Додатку 3 Оголошення.'\n",
    "#test_sent = 'Інформація в довільній формі за власноручним підписом фізичної особи, яка є учасником та завірена печаткою (у разі наявності) про те, що фізична особа, яка є учасником, не була засуджена за злочин, учинений з корисливих мотивів (зокрема, повязаний з хабарництвом та відмиванням коштів), судимість з якої не знято або не погашено у встановленому законом порядку'\n",
    "#test_sent = 'Копія свідоцтва про реєстрацію платника ПДВ або витягу з реєстру платників ПДВ або копія свідоцтва сплати єдиного податку або копія витягу з реєстру платників єдиного податку'\n",
    "#test_sent = 'Копія виписки з Єдиного державного реєстру юридичних осіб'\n",
    "#test_sent = 'Оригінал або нотаріально завірена копія документу (-ів) видану уповноваженим органам про те, що, службова (посадова) особа учасника, яку уповноважено учасником представляти його інтереси під час проведення процедури закупівлі не була засуджена за злочин, вчинений з корисливих мотивів, судимість з якої не знято або не погашено у встановленому законом порядку.'\n",
    "#test_sent = 'asdvasbasdfnbsadfbn'\n",
    "\n",
    "model = joblib.load(vec_path)\n",
    "clf = joblib.load(clf_path)\n",
    "\n",
    "empty_label = '?'\n",
    "true_positive,false_positive = [],[]\n",
    "cnt,label_cnt,false_cnt = 0,0,0\n",
    "pbar = tqdm(range(1, txt_data.shape[0]))\n",
    "for i in pbar:\n",
    "    text = txt_data['text'][i]\n",
    "    if not isinstance(text, str):\n",
    "        continue\n",
    "    \n",
    "    text_vector = ivec(normalize(text), model)\n",
    "    prediction = clf.predict(scaler.transform([text_vector]))\n",
    "    label_name = map_label(label_dct, index=prediction[0])\n",
    "    if label_name != empty_label:\n",
    "        label_cnt += 1\n",
    "    \n",
    "    if prediction[0] != map_label(label_dct, name=empty_label):\n",
    "        \n",
    "        if label_name == txt_data['label_name'][i]:\n",
    "            true_positive.append((map_label(label_dct, index=prediction[0]), text))\n",
    "            cnt += 1\n",
    "        else:\n",
    "            false_positive.append((map_label(label_dct, index=prediction[0]), text, txt_data['label_name'][i]))\n",
    "            false_cnt +=1\n",
    "        pbar.set_postfix({'docs found {} of total {}, false items {}'.format(cnt, label_cnt, false_cnt): (cnt/label_cnt)*100})\n",
    "            \n",
    "        if cnt == 10:\n",
    "            break\n",
    "        \n",
    "print('Found sentences about documents {} from total {}'.format(len(true_positive), label_cnt))\n",
    "\n",
    "for doc in false_positive:\n",
    "    print('---- (pred) {} (real) {}:\\n{}'.format(doc[0], doc[2],doc[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (tender_cat)",
   "language": "python",
   "name": "pycharm-59b3698e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
